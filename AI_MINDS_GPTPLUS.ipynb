{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzzfE15qjrcH"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import tempfile\n",
        "from gtts import gTTS\n",
        "import re\n",
        "import graphviz\n",
        "import os\n",
        "\n",
        "# Load the API key from environment variables for security\n",
        "API_KEY = 'c11088e2e97542b09e8aa2e9b93311d9'\n",
        "\n",
        "# Define API endpoints\n",
        "IMAGE_API_URL = 'https://api.aimlapi.com/images/generations'\n",
        "CHAT_API_URL = 'https://api.aimlapi.com/chat/completions'\n",
        "\n",
        "# List of available chat models\n",
        "CHAT_MODELS = [\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\n",
        "    \"meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\n",
        "    \"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct-Turbo\",\n",
        "    \"gpt-4o\",\n",
        "    \"gpt-4o-mini-2024-07-18\"\n",
        "]\n",
        "\n",
        "# Load supported languages from a file\n",
        "def load_languages(file_path='languages.txt'):\n",
        "    languages = {}\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                if line.strip():\n",
        "                    language, code = line.strip().split(': ')\n",
        "                    languages[language] = code\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found.\")\n",
        "    return languages\n",
        "\n",
        "languages = load_languages()\n",
        "\n",
        "def get_answer_content(language_name, question, model_name, category, max_chars, max_lines):\n",
        "    language_code = languages.get(language_name, 'en')\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {API_KEY}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": model_name,\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Respond in {language_name} for category '{category}': {question}\"\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 1500,\n",
        "        \"stream\": False\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(CHAT_API_URL, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        answer_content = response.json()['choices'][0]['message']['content']\n",
        "\n",
        "        if category in [\"Documentation\", \"Research\"]:\n",
        "            answer_content = answer_content[:1500]\n",
        "\n",
        "        # Truncate to max_chars\n",
        "        if max_chars:\n",
        "            answer_content = answer_content[:int(max_chars)]\n",
        "\n",
        "        # Ensure the output ends with a complete sentence\n",
        "        if max_chars:\n",
        "            truncated_length = int(max_chars)\n",
        "            if truncated_length < len(answer_content):\n",
        "                # Find the last sentence-ending punctuation within the truncated length\n",
        "                last_punctuation_index = max(\n",
        "                    answer_content.rfind(p) for p in \".!?\"\n",
        "                )\n",
        "                if last_punctuation_index > -1 and last_punctuation_index <= truncated_length:\n",
        "                    answer_content = answer_content[:last_punctuation_index + 1]\n",
        "                else:\n",
        "                    # If no punctuation is found or it's outside the limit, truncate at the limit\n",
        "                    answer_content = answer_content[:truncated_length]\n",
        "\n",
        "        # Limit by max_lines if specified\n",
        "        if max_lines:\n",
        "            answer_content = \"\\n\".join(answer_content.splitlines()[:int(max_lines)])\n",
        "\n",
        "        # Remove unwanted introductory lines\n",
        "        lines = answer_content.splitlines()\n",
        "        filtered_lines = [line for line in lines if not line.lower().startswith(\"here's a joke about\")]\n",
        "        filtered_content = \"\\n\".join(filtered_lines)\n",
        "\n",
        "        return filtered_content\n",
        "    except requests.RequestException as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return re.sub(r'[^\\w\\s,.!?]', '', text)\n",
        "\n",
        "def text_to_speech_online(text, lang='en'):\n",
        "    try:\n",
        "        cleaned_text = preprocess_text(text)\n",
        "        tts = gTTS(text=cleaned_text, lang=lang, slow=False)\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as temp_file:\n",
        "            tts.save(temp_file.name)\n",
        "            return temp_file.name\n",
        "    except Exception as e:\n",
        "        print(f\"Text-to-speech failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_image(prompt, model_name):\n",
        "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "    payload = {\"prompt\": prompt, \"model\": model_name}\n",
        "    try:\n",
        "        response = requests.post(IMAGE_API_URL, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        output = response.json()\n",
        "        if \"images\" in output and output[\"images\"]:\n",
        "            image_url = output[\"images\"][0][\"url\"]\n",
        "            img_data = requests.get(image_url).content\n",
        "            image = Image.open(BytesIO(img_data))\n",
        "            return image\n",
        "        else:\n",
        "            print(\"Unexpected response structure:\", output)\n",
        "            return Image.new('RGB', (512, 512), color=(255, 0, 0))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return Image.new('RGB', (512, 512), color=(255, 0, 0))\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return Image.new('RGB', (512, 512), color=(255, 0, 0))\n",
        "\n",
        "def wrap_text(text, width=30):\n",
        "    words = text.split()\n",
        "    lines, current_line, current_length = [], [], 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) <= width:\n",
        "            current_line.append(word)\n",
        "            current_length += len(word) + 1\n",
        "        else:\n",
        "            lines.append(\" \".join(current_line))\n",
        "            current_line = [word]\n",
        "            current_length = len(word) + 1\n",
        "\n",
        "    lines.append(\" \".join(current_line))\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def generate_workflow_diagram(steps):\n",
        "    dot = graphviz.Digraph(format='png')\n",
        "    dot.attr(rankdir='TB', size='10,10', nodesep='0.5', ranksep='0.5', dpi='300')\n",
        "\n",
        "    steps = steps.strip().split(\"\\n\")\n",
        "    if not steps or steps == [\"\"]:\n",
        "        return None\n",
        "\n",
        "    for i, step in enumerate(steps):\n",
        "        step = wrap_text(step.strip(), width=30)\n",
        "        if step:\n",
        "            dot.node(str(i), step, shape='box', width='2.0', height='0.5', fontsize='12')\n",
        "            if i > 0:\n",
        "                dot.edge(str(i - 1), str(i))\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_file:\n",
        "        dot.render(temp_file.name)\n",
        "        return temp_file.name + '.png'\n",
        "\n",
        "def on_button_click(language_name, question, model_name, category, max_chars, max_lines):\n",
        "    if not question.strip():\n",
        "        return \"Please enter a question.\", None\n",
        "\n",
        "    if category == \"default\":\n",
        "        category = \"Post\"\n",
        "\n",
        "    answer = get_answer_content(language_name, question, model_name, category, max_chars, max_lines)\n",
        "    audio_file = text_to_speech_online(answer, languages.get(language_name, 'en'))\n",
        "\n",
        "    return f\"You: {question}\\n\\nAI MINDS:\\n\\n{answer}\", audio_file\n",
        "\n",
        "def on_image_button_click(prompt, model_name):\n",
        "    return generate_image(prompt, model_name)\n",
        "\n",
        "def on_workflow_button_click(steps):\n",
        "    return generate_workflow_diagram(steps)\n",
        "\n",
        "def clear_all():\n",
        "    return None, None, None, None, None\n",
        "\n",
        "# Define Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# AI_MINDS_GPTPLUS\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Chat\"):\n",
        "            gr.Markdown(\"## Chat Section\")\n",
        "            with gr.Row():\n",
        "                language_dropdown = gr.Dropdown(choices=list(languages.keys()), label=\"Select Language\", value=\"English\")\n",
        "                model_dropdown = gr.Dropdown(choices=CHAT_MODELS, label=\"Select Chat Model\", value=\"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\")\n",
        "                category_dropdown = gr.Dropdown(choices=[\"default\",\"Post\", \"Documentation\", \"Research\", \"Generation\"], label=\"Select Category\", value=\"default\")\n",
        "                max_chars_input = gr.Number(label=\"Max Characters (Optional)\", value=None, step=1, precision=0)\n",
        "                max_lines_input = gr.Number(label=\"Max Lines (Optional)\", value=None, step=1, precision=0)\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    question_input = gr.Textbox(label=\"Your Question\", placeholder='Ask a question...', lines=2)\n",
        "                    generate_button = gr.Button(\"Ask\")\n",
        "                    small_audio_output = gr.Audio(label=\"Voice Output\", type=\"filepath\", visible=True, interactive=False)\n",
        "                    clear_button = gr.Button(\"Clear\")\n",
        "\n",
        "                with gr.Column(scale=2):\n",
        "                    content_output = gr.Markdown(label=\"Chat Output\")\n",
        "\n",
        "        with gr.Tab(\"Image\"):\n",
        "            gr.Markdown(\"## Image Generation Section\")\n",
        "            image_prompt = gr.Textbox(label=\"Image Prompt\", placeholder='Enter an image prompt...')\n",
        "            image_model_dropdown = gr.Dropdown(choices=[\"flux-realism\", \"stable-diffusion-v3-medium\"], label=\"Select Image Model\", value=\"flux-realism\")\n",
        "            generated_image = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
        "            image_generate_button = gr.Button(\"Generate Image\")\n",
        "\n",
        "        with gr.Tab(\"Flowchart\"):\n",
        "            gr.Markdown(\"## Workflow Diagram Generator\")\n",
        "            workflow_input = gr.Textbox(lines=10, placeholder=\"Enter workflow steps, one per line.\", label=\"Workflow Steps\")\n",
        "            generate_workflow_button = gr.Button(\"Generate Diagram\")\n",
        "            diagram_output = gr.Image(label=\"Generated Workflow Diagram\")\n",
        "\n",
        "    # Define button actions\n",
        "    generate_button.click(on_button_click, [language_dropdown, question_input, model_dropdown, category_dropdown, max_chars_input, max_lines_input], [content_output, small_audio_output])\n",
        "    image_generate_button.click(on_image_button_click, [image_prompt, image_model_dropdown], [generated_image])\n",
        "    generate_workflow_button.click(on_workflow_button_click, [workflow_input], [diagram_output])\n",
        "\n",
        "    clear_button.click(fn=clear_all, inputs=[], outputs=[question_input, content_output, generated_image, diagram_output, small_audio_output])\n",
        "\n",
        "# Launch the Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEcpQMfqj8g7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}